---
title: Queue & Workers
description: Background job processing with multi-strategy queues supporting local file-based and Redis-backed (BullMQ) strategies.
---

# Queue & Workers

The `@open-mercato/queue` package provides a multi-strategy job queue system for reliable background processing. It integrates seamlessly with the [Events system](./overview.mdx) to handle persistent events asynchronously.

## Overview

The queue system supports two strategies:

| Strategy | Backend | Use Case | Persistence |
|----------|---------|----------|-------------|
| `local` | File system (JSON) | Development, single-instance deployments | `.queue/<name>/queue.json` |
| `async` | Redis (BullMQ) | Production, multi-instance deployments | Redis sorted sets |

## Quick Start

```typescript
import { createQueue } from '@open-mercato/queue'

// Create a queue
const queue = createQueue<{ userId: string }>('notifications', 'local')

// Add a job to the queue
await queue.enqueue({ userId: '123' })

// Process jobs
await queue.process(async (job, ctx) => {
  console.log(`Processing job ${ctx.jobId}:`, job.payload)
})
```

## Queue Strategies

### Local Strategy

The local strategy stores jobs in JSON files, making it ideal for development and simple deployments without Redis.

:::danger Production Warning
**Never use the local strategy in production.** It is filesystem-based and does not support distributed systems, concurrent access from multiple processes, or high availability. Always use the `async` (Redis/BullMQ) strategy for production deployments.
:::

```typescript
import { createQueue } from '@open-mercato/queue'

const queue = createQueue<MyJobData>('my-queue', 'local', {
  baseDir: '.queue' // Optional, defaults to '.queue'
})
```

**File structure:**
```
.queue/
  my-queue/
    queue.json   # Array of queued jobs
    state.json   # Processing state (last processed ID)
```

**Characteristics:**
- Synchronous processing via `queue.process()`
- Jobs persist across restarts
- No external dependencies
- Single-process only (not suitable for distributed systems)

### Async Strategy (BullMQ)

The async strategy uses Redis via BullMQ for production-grade job processing with concurrent workers.

```typescript
import { createQueue } from '@open-mercato/queue'

const queue = createQueue<MyJobData>('my-queue', 'async', {
  connection: {
    url: 'redis://localhost:6379',
    // Or use individual options:
    // host: 'localhost',
    // port: 6379,
    // password: 'secret'
  },
  concurrency: 5 // Number of concurrent job processors
})
```

**Environment variables:**
- `REDIS_URL` or `QUEUE_REDIS_URL` - Redis connection URL (fallback if not provided in options)

**Characteristics:**
- Persistent job storage in Redis
- Automatic retries with exponential backoff
- Concurrent job processing
- Distributed across multiple instances
- Job prioritization and scheduling

## Queue Interface

All queues implement the same interface regardless of strategy:

```typescript
interface Queue<T> {
  readonly name: string
  readonly strategy: 'local' | 'async'

  // Add a job to the queue
  enqueue(data: T): Promise<string>

  // Process jobs from the queue
  process(handler: JobHandler<T>, options?: ProcessOptions): Promise<ProcessResult>

  // Remove all jobs
  clear(): Promise<{ removed: number }>

  // Close the queue and release resources
  close(): Promise<void>

  // Get current job counts by status
  getJobCounts(): Promise<{
    waiting: number
    active: number
    completed: number
    failed: number
  }>
}
```

## Job Handler

The job handler receives the job data and a context object:

```typescript
type JobHandler<T> = (job: QueuedJob<T>, ctx: JobContext) => Promise<void> | void

type QueuedJob<T> = {
  id: string
  payload: T
  createdAt: string
  metadata?: Record<string, unknown>
}

type JobContext = {
  jobId: string
  attemptNumber: number  // 1-based attempt count
  queueName: string
}
```

**Example:**

```typescript
await queue.process(async (job, ctx) => {
  console.log(`[${ctx.queueName}] Processing job ${ctx.jobId} (attempt ${ctx.attemptNumber})`)

  const { userId } = job.payload
  await sendNotification(userId)
})
```

## Running Workers

For production deployments, run dedicated worker processes that continuously process jobs.

### Unified Entrypoint (Development Only)

Open Mercato provides a unified entrypoint that runs both the Next.js app and all queue workers automatically:

```bash
# Development mode with workers (default)
npm run dev
```

When you run this command, the system automatically:
1. Starts the Next.js application
2. Spawns a worker process that handles ALL discovered queues

:::danger Production Warning
**Never use the unified entrypoint with auto-spawned workers in production.** In production, you should:
1. Set `AUTO_SPAWN_WORKERS=false`
2. Run worker processes separately using `npm run start:workers` or `yarn mercato queue worker --all`

This separation allows you to:
- Scale workers independently from the web application
- Deploy workers on dedicated machines
- Restart workers without affecting the main application
- Monitor and manage worker processes separately
:::

#### Controlling Worker Auto-Spawn

Use the `AUTO_SPAWN_WORKERS` environment variable to control this behavior:

```bash
# .env
AUTO_SPAWN_WORKERS=true  # Default: spawn workers automatically
```

Set to `false` for production deployments where you want to run workers separately for scaling:

```bash
AUTO_SPAWN_WORKERS=false npm run start
```

#### Available Scripts

| Script | Description |
|--------|-------------|
| `npm run dev` | Development mode with workers |
| `npm run start` | Production mode with workers |
| `npm run dev:app` | Development mode (app only) |
| `npm run start:app` | Production mode (app only) |
| `npm run start:workers` | Run workers only (all queues) |

### Running All Workers via CLI

The `--all` flag processes jobs from all discovered queues in a single process:

```bash
# Process all queues
yarn mercato queue worker --all

# Via npm script
npm run start:workers
```

This starts workers for all registered queues (e.g., `events`, `fulltext-indexing`, `vector-indexing`).

### Running a Single Queue

For fine-grained control, run workers for specific queues:

```bash
# Start a worker for a specific queue
yarn mercato queue worker events

# With custom concurrency
yarn mercato queue worker events --concurrency=5
```

### Using `runWorker` Programmatically

```typescript
import { runWorker } from '@open-mercato/queue/worker'

await runWorker({
  queueName: 'events',
  handler: async (job, ctx) => {
    console.log(`Processing ${ctx.jobId}:`, job.payload)
  },
  connection: { url: process.env.REDIS_URL },
  concurrency: 5,
  gracefulShutdown: true // Handle SIGTERM/SIGINT
})
```

The worker will:
1. Connect to Redis and start a BullMQ worker
2. Process jobs continuously with the specified concurrency
3. Gracefully shutdown on SIGTERM/SIGINT signals

### Routed Handlers

For queues with multiple job types, use `createRoutedHandler`:

```typescript
import { runWorker, createRoutedHandler } from '@open-mercato/queue/worker'

const handler = createRoutedHandler({
  'user.created': async (job, ctx) => {
    await sendWelcomeEmail(job.payload.email)
  },
  'order.placed': async (job, ctx) => {
    await notifyWarehouse(job.payload.orderId)
  },
  'payment.received': async (job, ctx) => {
    await updateAccountBalance(job.payload)
  },
})

await runWorker({
  queueName: 'events',
  handler,
  concurrency: 10,
})
```

Jobs must have a `type` field in their payload to route correctly.

## Integration with Events

Persistent events (`persistent: true`) are automatically queued for async processing. The event system uses the queue package under the hood.

### Subscriber with Persistent Events

```typescript
// src/modules/orders/subscribers/order-created.ts
export const metadata = {
  event: 'order.created',
  persistent: true, // This event will be queued
}

export default async function handle(
  payload: { orderId: string; total: number },
  ctx: { resolve: <T>(name: string) => T }
) {
  const emailService = ctx.resolve('emailService')
  await emailService.sendOrderConfirmation(payload.orderId)
}
```

### Processing Persistent Events

Persistent events are processed by running a queue worker via the CLI:

```bash
# Start a worker to process events continuously
yarn mercato queue worker events

# With custom concurrency
yarn mercato queue worker events --concurrency=5

# Check queue status
yarn mercato queue status events

# Clear all queued events
yarn mercato queue clear events

# Emit an event (for testing)
yarn mercato events emit order.created '{"id":123}' --persistent
```

## Configuration

### Strategy Selection

Set the queue strategy via environment variable:

```bash
# Use local file-based queue (default)
EVENTS_STRATEGY=local

# Use Redis-backed queue
EVENTS_STRATEGY=redis
```

### Redis Configuration

```bash
# Primary Redis URL
REDIS_URL=redis://localhost:6379

# Or use events-specific URL
EVENTS_REDIS_URL=redis://events-redis:6379

# Queue-specific URL
QUEUE_REDIS_URL=redis://queue-redis:6379
```

## Best Practices

### 1. Use Persistent Events for Side Effects

```typescript
// Good: Email sending should be async
await bus.emitEvent('user.registered', { userId }, { persistent: true })

// Good: Inline for immediate state updates
await bus.emitEvent('cache.invalidated', { key }, { persistent: false })
```

### 2. Make Handlers Idempotent

Jobs may be retried on failure. Design handlers to be safely re-executed:

```typescript
async function handlePayment(job, ctx) {
  const { paymentId } = job.payload

  // Check if already processed
  const existing = await db.findPayment(paymentId)
  if (existing.status === 'completed') {
    return // Already processed, skip
  }

  await processPayment(paymentId)
}
```

### 3. Set Appropriate Concurrency

```typescript
// CPU-bound tasks: match CPU cores
createQueue('image-processing', 'async', { concurrency: 4 })

// I/O-bound tasks: higher concurrency
createQueue('api-calls', 'async', { concurrency: 20 })

// Rate-limited external APIs: lower concurrency
createQueue('email-sending', 'async', { concurrency: 2 })
```

### 4. Monitor Job Counts

```typescript
const counts = await queue.getJobCounts()
console.log(`Waiting: ${counts.waiting}, Active: ${counts.active}, Failed: ${counts.failed}`)

if (counts.failed > 100) {
  alertOps('High failure rate in queue')
}
```

## Type Definitions

```typescript
// Queue strategy types
type QueueStrategyType = 'local' | 'async'

// Options for local strategy
type LocalQueueOptions = {
  baseDir?: string // Default: '.queue'
}

// Options for async strategy
type AsyncQueueOptions = {
  connection?: {
    url?: string
    host?: string
    port?: number
    password?: string
  }
  concurrency?: number // Default: 1
}

// Process options
type ProcessOptions = {
  limit?: number // Max jobs to process (local strategy only)
}

// Process result
type ProcessResult = {
  processed: number
  failed: number
  lastJobId?: string
}
```

## Worker Auto-Discovery

Open Mercato automatically discovers workers from modules following a naming convention. This allows you to define workers alongside your module code.

### File Convention

Place worker files in your module's `workers/` directory with the `.worker.ts` suffix:

```
src/modules/<module>/workers/
  └── <queue-name>.worker.ts

# or in packages
packages/<package>/src/modules/<module>/workers/
  └── <queue-name>.worker.ts
```

### Worker File Structure

Each worker file must export:
1. `metadata` - Worker configuration (`WorkerMeta` type)
2. `default` - Handler function

```typescript
// src/modules/notifications/workers/email.worker.ts
import type { QueuedJob, JobContext, WorkerMeta } from '@open-mercato/queue'

// Required: Export metadata for auto-discovery
export const metadata: WorkerMeta = {
  queue: 'email-notifications',
  concurrency: parseInt(process.env.WORKERS_EMAIL_CONCURRENCY || '2', 10),
}

type EmailJobPayload = {
  to: string
  subject: string
  body: string
}

// Required: Export default handler function
export default async function handle(
  job: QueuedJob<EmailJobPayload>,
  ctx: JobContext
): Promise<void> {
  const { to, subject, body } = job.payload
  console.log(`[email-worker] Sending email to ${to}: ${subject}`)
  // Your job processing logic here
}
```

### WorkerMeta Type

```typescript
type WorkerMeta = {
  /** Queue name this worker processes */
  queue: string
  /** Optional unique identifier (defaults to <module>:workers:<filename>) */
  id?: string
  /** Worker concurrency (default: 1) */
  concurrency?: number
}
```

### Per-Queue Concurrency

Control concurrency per queue via environment variables:

```bash
# Format: WORKERS_<QUEUE_NAME>_CONCURRENCY
WORKERS_EVENTS_CONCURRENCY=5
WORKERS_EMAIL_NOTIFICATIONS_CONCURRENCY=2
WORKERS_FULLTEXT_INDEXING_CONCURRENCY=10
```

### Existing Workers

Open Mercato includes these built-in workers:

| Worker | Queue | Purpose |
|--------|-------|---------|
| `events.worker.ts` | `events` | Dispatches persistent events to subscribers |
| `fulltext-index.worker.ts` | `fulltext-indexing` | Indexes documents for Meilisearch |
| `vector-index.worker.ts` | `vector-indexing` | Generates embeddings for vector search |
